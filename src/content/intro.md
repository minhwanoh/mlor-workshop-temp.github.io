This workshop explores using programmatic representations (e.g., code, symbolic programs, rules) to enhance agent learning and address key challenges in creating autonomous agents.  By leveraging structured representations, we aim to improve interpretability, generalization, efficiency, and safety in agent systems, moving beyond the limitations of "black box" deep learning models.  The workshop brings together researchers in sequential decision-making and program synthesis/code generation to discuss using **programs as policies** (e.g., <a href="https://arxiv.org/abs/2108.13643"><span style="color:blue">LEAPS</span></a>, <a href="https://arxiv.org/abs/2209.07753"><span style="color:blue">Code as Policies</span></a>
, <a href="https://arxiv.org/abs/2310.13065"><span style="color:blue">RoboTool</span></a>, <a href="https://arxiv.org/abs/2410.12166"><span style="color:blue">Carvalho et al. 2024</span></a>), **reward functions** (e.g., <a href="https://arxiv.org/abs/2310.12931"><span style="color:blue">Eureka</span></a>, <a href="https://arxiv.org/abs/2306.08647"><span style="color:blue">Language2Reward</span></a>, <a href="https://arxiv.org/abs/2309.11489"><span style="color:blue">Text2Reward</span></a>), **skill libraries** (e.g., <a href="https://arxiv.org/abs/2305.16291"><span style="color:blue">Voyager</span></a>), **task generators** (e.g., <a href="https://arxiv.org/abs/2310.01361"><span style="color:blue">GenSim</span></a>), and **environment models** (e.g., <a href="https://arxiv.org/abs/2402.12275"><span style="color:blue">WorldCoder</span></a>, <a href="https://arxiv.org/abs/2405.15383"><span style="color:blue">Code World Models</span></a>), ultimately driving progress toward robust, understandable, and adaptable autonomous agents across diverse applications.
