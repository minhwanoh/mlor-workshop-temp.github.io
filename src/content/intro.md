This workshop explores using programmatic representations (code, symbolic programs, rules) to enhance agent learning and address key challenges in creating autonomous agents.  By leveraging structured representations, we aim to improve interpretability, generalization, efficiency, and safety in agent systems, moving beyond the limitations of "black box" deep learning models.  The workshop brings together researchers in sequential decision-making and program synthesis/code generation to discuss using programs as policies (e.g., Code as Policies, RoboTool), reward functions (e.g., Eureka), task generators (e.g., GenSim), and environment models (e.g., WorldCoder), ultimately driving progress toward robust, understandable, and adaptable autonomous agents across diverse applications.